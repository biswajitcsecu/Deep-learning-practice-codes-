{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img('data/train/cats/cat.1000.jpg')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='data/preview', save_prefix='cat', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=( 150, 150,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/val',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 81s 648ms/step - loss: 0.7416 - acc: 0.5455 - val_loss: 0.6756 - val_acc: 0.5675\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 84s 670ms/step - loss: 0.6543 - acc: 0.6140 - val_loss: 0.8415 - val_acc: 0.5050\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 85s 679ms/step - loss: 0.5895 - acc: 0.7025 - val_loss: 0.6393 - val_acc: 0.6512\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 83s 661ms/step - loss: 0.5336 - acc: 0.7475 - val_loss: 0.8007 - val_acc: 0.6462\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 88s 701ms/step - loss: 0.4663 - acc: 0.7975 - val_loss: 0.7395 - val_acc: 0.6538\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 79s 634ms/step - loss: 0.4227 - acc: 0.8060 - val_loss: 0.8378 - val_acc: 0.6650\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 81s 644ms/step - loss: 0.3550 - acc: 0.8540 - val_loss: 0.7798 - val_acc: 0.6775\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 80s 638ms/step - loss: 0.3079 - acc: 0.8660 - val_loss: 1.2833 - val_acc: 0.6275\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 81s 649ms/step - loss: 0.2862 - acc: 0.8865 - val_loss: 0.9922 - val_acc: 0.6875\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 80s 638ms/step - loss: 0.2324 - acc: 0.9095 - val_loss: 1.2313 - val_acc: 0.6575\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 81s 646ms/step - loss: 0.2167 - acc: 0.9225 - val_loss: 1.1897 - val_acc: 0.6775\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 80s 640ms/step - loss: 0.1974 - acc: 0.9250 - val_loss: 1.3123 - val_acc: 0.6600\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 79s 634ms/step - loss: 0.1674 - acc: 0.9395 - val_loss: 1.5293 - val_acc: 0.6625\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 81s 646ms/step - loss: 0.1673 - acc: 0.9450 - val_loss: 1.1940 - val_acc: 0.6713\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 80s 639ms/step - loss: 0.1468 - acc: 0.9505 - val_loss: 2.6573 - val_acc: 0.5737\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 81s 648ms/step - loss: 0.1566 - acc: 0.9470 - val_loss: 1.8232 - val_acc: 0.6763\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 83s 663ms/step - loss: 0.1532 - acc: 0.9510 - val_loss: 2.0054 - val_acc: 0.6425\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 81s 645ms/step - loss: 0.1564 - acc: 0.9520 - val_loss: 2.9297 - val_acc: 0.6550\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 86s 688ms/step - loss: 0.1264 - acc: 0.9615 - val_loss: 1.9160 - val_acc: 0.6625\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 82s 653ms/step - loss: 0.1300 - acc: 0.9595 - val_loss: 1.9308 - val_acc: 0.6737\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 86s 688ms/step - loss: 0.1369 - acc: 0.9560 - val_loss: 1.5476 - val_acc: 0.6737\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 86s 686ms/step - loss: 0.1524 - acc: 0.9520 - val_loss: 2.2189 - val_acc: 0.6675\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 84s 670ms/step - loss: 0.1295 - acc: 0.9585 - val_loss: 2.3379 - val_acc: 0.6687\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 81s 647ms/step - loss: 0.1548 - acc: 0.9570 - val_loss: 2.0818 - val_acc: 0.6675\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 79s 630ms/step - loss: 0.1259 - acc: 0.9600 - val_loss: 2.6308 - val_acc: 0.6587\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 80s 643ms/step - loss: 0.1284 - acc: 0.9570 - val_loss: 2.3573 - val_acc: 0.6475\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 81s 647ms/step - loss: 0.1191 - acc: 0.9665 - val_loss: 2.7399 - val_acc: 0.6737\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 85s 677ms/step - loss: 0.1337 - acc: 0.9615 - val_loss: 2.1959 - val_acc: 0.6700\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 85s 676ms/step - loss: 0.1257 - acc: 0.9615 - val_loss: 2.2566 - val_acc: 0.6400\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 83s 662ms/step - loss: 0.1287 - acc: 0.9610 - val_loss: 2.9608 - val_acc: 0.6562\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 87s 692ms/step - loss: 0.1208 - acc: 0.9700 - val_loss: 2.6254 - val_acc: 0.6637\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 82s 660ms/step - loss: 0.1232 - acc: 0.9635 - val_loss: 2.7295 - val_acc: 0.6713\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 81s 647ms/step - loss: 0.1126 - acc: 0.9650 - val_loss: 2.8587 - val_acc: 0.6600\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 80s 641ms/step - loss: 0.1406 - acc: 0.9640 - val_loss: 2.1121 - val_acc: 0.6763\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 80s 641ms/step - loss: 0.1623 - acc: 0.9625 - val_loss: 2.0337 - val_acc: 0.6763\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 82s 653ms/step - loss: 0.1378 - acc: 0.9590 - val_loss: 2.6045 - val_acc: 0.6637\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 84s 675ms/step - loss: 0.1366 - acc: 0.9605 - val_loss: 2.1848 - val_acc: 0.6663\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 81s 645ms/step - loss: 0.1350 - acc: 0.9605 - val_loss: 3.3255 - val_acc: 0.6275\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 79s 633ms/step - loss: 0.1504 - acc: 0.9680 - val_loss: 2.5991 - val_acc: 0.6663\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 82s 657ms/step - loss: 0.1235 - acc: 0.9670 - val_loss: 2.5479 - val_acc: 0.6637\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 81s 647ms/step - loss: 0.1512 - acc: 0.9660 - val_loss: 2.9751 - val_acc: 0.6562\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 84s 671ms/step - loss: 0.1600 - acc: 0.9595 - val_loss: 2.3557 - val_acc: 0.6475\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 83s 667ms/step - loss: 0.1362 - acc: 0.9665 - val_loss: 2.1261 - val_acc: 0.6538\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 83s 665ms/step - loss: 0.1476 - acc: 0.9660 - val_loss: 3.1217 - val_acc: 0.6600\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 81s 649ms/step - loss: 0.1760 - acc: 0.9535 - val_loss: 2.3946 - val_acc: 0.6562\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 80s 639ms/step - loss: 0.1404 - acc: 0.9615 - val_loss: 3.4044 - val_acc: 0.6713\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 83s 663ms/step - loss: 0.1654 - acc: 0.9565 - val_loss: 2.8893 - val_acc: 0.6575\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 79s 629ms/step - loss: 0.1689 - acc: 0.9570 - val_loss: 2.7689 - val_acc: 0.6500\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 83s 662ms/step - loss: 0.1284 - acc: 0.9680 - val_loss: 2.9656 - val_acc: 0.6775\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 153s 1s/step - loss: 0.1742 - acc: 0.9630 - val_loss: 3.4166 - val_acc: 0.6725\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)\n",
    "model.save_weights('first_try.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-feb6ee4b8853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mbottleneck_features_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# save the output as a Numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bottleneck_features_train.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottleneck_features_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m generator = datagen.flow_from_directory(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # this means our generator will only yield batches of data, no labels\n",
    "        shuffle=False)  # our data will be in order, so all first 1000 images will be cats, then 1000 dogs\n",
    "# the predict_generator method returns the output of a model, given\n",
    "# a generator that yields batches of numpy data\n",
    "bottleneck_features_train = model.predict_generator(generator, 2000)\n",
    "# save the output as a Numpy array\n",
    "np.save(open('bottleneck_features_train.npy', 'w'), bottleneck_features_train)\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "bottleneck_features_validation = model.predict_generator(generator, 800)\n",
    "np.save(open('bottleneck_features_validation.npy', 'w'), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(open('bottleneck_features_train.npy'))\n",
    "# the features were saved in order, so recreating the labels is easy\n",
    "train_labels = np.array([0] * 1000 + [1] * 1000)\n",
    "\n",
    "validation_data = np.load(open('bottleneck_features_validation.npy'))\n",
    "validation_labels = np.array([0] * 400 + [1] * 400)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          epochs=50,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(validation_data, validation_labels))\n",
    "model.save_weights('bottleneck_fc_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "model.add(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:25]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
